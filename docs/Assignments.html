<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Assignments</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics for the Social Sciences</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Assignments.html">Assignments</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Assignments</h1>

</div>


<p>This page will contain all the assignments you submit for the class.</p>
<div id="instructions-for-all-assignments" class="section level3">
<h3>Instructions for all assignments</h3>
<p>I want you to submit your assignment as a PDF, so I can keep a record of what the code looked like that day. I also want you to include your answers on your personal GitHub website. This will be good practice for editing your website and it will help you produce something you can keep after the class is over.</p>
<ol style="list-style-type: decimal">
<li><p>Download the Assignment1.Rmd file from Canvas. You can use this as a template for writing your answers. It’s the same as what you can see on my website in the Assignments tab. Once we’re done with this I’ll edit the text on the website to include the solutions.</p></li>
<li><p>On RStudio, open a new R script in RStudio (File &gt; New File &gt; R Script). This is where you can test out your R code. You’ll write your R commands and draw plots here.</p></li>
<li><p>Once you have finalized your code, copy and paste your results into this template (Assignment 1.Rmd). For example, if you produced a plot as the solution to one of the problems, you can copy and paste the R code in R markdown by using the <code>``{r} ```</code> command. Answer the questions in full sentences and Save.</p></li>
<li><p>Produce a PDF file with your answers. To do this, knit to PDF (use Knit button at the top of RStudio), locate the PDF file in your docs folder (it’s in the same folder as the Rproj), and submit that on on Canvas in Assignment 1.</p></li>
<li><p>Build Website, go to GitHub desktop, commit and push. Now your solutions should be on your website as well.</p></li>
</ol>
</div>
<div id="assignment-1" class="section level1">
<h1>Assignment 1</h1>
<p><strong>Collaborators: Carmen Avery, Rachel Villari, and Halle Wasser. </strong></p>
<p>This assignment is due on Canvas on Monday 9/20 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<div id="problem-1" class="section level3">
<h3>Problem 1</h3>
<p>Install the datasets package on the console below using <code>install.packages("datasets")</code>. Now load the library.</p>
<pre class="r"><code>datasets::USArrests</code></pre>
<pre><code>##                Murder Assault UrbanPop Rape
## Alabama          13.2     236       58 21.2
## Alaska           10.0     263       48 44.5
## Arizona           8.1     294       80 31.0
## Arkansas          8.8     190       50 19.5
## California        9.0     276       91 40.6
## Colorado          7.9     204       78 38.7
## Connecticut       3.3     110       77 11.1
## Delaware          5.9     238       72 15.8
## Florida          15.4     335       80 31.9
## Georgia          17.4     211       60 25.8
## Hawaii            5.3      46       83 20.2
## Idaho             2.6     120       54 14.2
## Illinois         10.4     249       83 24.0
## Indiana           7.2     113       65 21.0
## Iowa              2.2      56       57 11.3
## Kansas            6.0     115       66 18.0
## Kentucky          9.7     109       52 16.3
## Louisiana        15.4     249       66 22.2
## Maine             2.1      83       51  7.8
## Maryland         11.3     300       67 27.8
## Massachusetts     4.4     149       85 16.3
## Michigan         12.1     255       74 35.1
## Minnesota         2.7      72       66 14.9
## Mississippi      16.1     259       44 17.1
## Missouri          9.0     178       70 28.2
## Montana           6.0     109       53 16.4
## Nebraska          4.3     102       62 16.5
## Nevada           12.2     252       81 46.0
## New Hampshire     2.1      57       56  9.5
## New Jersey        7.4     159       89 18.8
## New Mexico       11.4     285       70 32.1
## New York         11.1     254       86 26.1
## North Carolina   13.0     337       45 16.1
## North Dakota      0.8      45       44  7.3
## Ohio              7.3     120       75 21.4
## Oklahoma          6.6     151       68 20.0
## Oregon            4.9     159       67 29.3
## Pennsylvania      6.3     106       72 14.9
## Rhode Island      3.4     174       87  8.3
## South Carolina   14.4     279       48 22.5
## South Dakota      3.8      86       45 12.8
## Tennessee        13.2     188       59 26.9
## Texas            12.7     201       80 25.5
## Utah              3.2     120       80 22.9
## Vermont           2.2      48       32 11.2
## Virginia          8.5     156       63 20.7
## Washington        4.0     145       73 26.2
## West Virginia     5.7      81       39  9.3
## Wisconsin         2.6      53       66 10.8
## Wyoming           6.8     161       60 15.6</code></pre>
<pre class="r"><code>install.packages(&quot;datasets&quot;)
library(&quot;datasets&quot;)
USArrests</code></pre>
<pre><code>##                Murder Assault UrbanPop Rape
## Alabama          13.2     236       58 21.2
## Alaska           10.0     263       48 44.5
## Arizona           8.1     294       80 31.0
## Arkansas          8.8     190       50 19.5
## California        9.0     276       91 40.6
## Colorado          7.9     204       78 38.7
## Connecticut       3.3     110       77 11.1
## Delaware          5.9     238       72 15.8
## Florida          15.4     335       80 31.9
## Georgia          17.4     211       60 25.8
## Hawaii            5.3      46       83 20.2
## Idaho             2.6     120       54 14.2
## Illinois         10.4     249       83 24.0
## Indiana           7.2     113       65 21.0
## Iowa              2.2      56       57 11.3
## Kansas            6.0     115       66 18.0
## Kentucky          9.7     109       52 16.3
## Louisiana        15.4     249       66 22.2
## Maine             2.1      83       51  7.8
## Maryland         11.3     300       67 27.8
## Massachusetts     4.4     149       85 16.3
## Michigan         12.1     255       74 35.1
## Minnesota         2.7      72       66 14.9
## Mississippi      16.1     259       44 17.1
## Missouri          9.0     178       70 28.2
## Montana           6.0     109       53 16.4
## Nebraska          4.3     102       62 16.5
## Nevada           12.2     252       81 46.0
## New Hampshire     2.1      57       56  9.5
## New Jersey        7.4     159       89 18.8
## New Mexico       11.4     285       70 32.1
## New York         11.1     254       86 26.1
## North Carolina   13.0     337       45 16.1
## North Dakota      0.8      45       44  7.3
## Ohio              7.3     120       75 21.4
## Oklahoma          6.6     151       68 20.0
## Oregon            4.9     159       67 29.3
## Pennsylvania      6.3     106       72 14.9
## Rhode Island      3.4     174       87  8.3
## South Carolina   14.4     279       48 22.5
## South Dakota      3.8      86       45 12.8
## Tennessee        13.2     188       59 26.9
## Texas            12.7     201       80 25.5
## Utah              3.2     120       80 22.9
## Vermont           2.2      48       32 11.2
## Virginia          8.5     156       63 20.7
## Washington        4.0     145       73 26.2
## West Virginia     5.7      81       39  9.3
## Wisconsin         2.6      53       66 10.8
## Wyoming           6.8     161       60 15.6</code></pre>
<pre class="r"><code>dat&lt;-USArrests # renames USArrests as dat
dat</code></pre>
<pre><code>##                Murder Assault UrbanPop Rape
## Alabama          13.2     236       58 21.2
## Alaska           10.0     263       48 44.5
## Arizona           8.1     294       80 31.0
## Arkansas          8.8     190       50 19.5
## California        9.0     276       91 40.6
## Colorado          7.9     204       78 38.7
## Connecticut       3.3     110       77 11.1
## Delaware          5.9     238       72 15.8
## Florida          15.4     335       80 31.9
## Georgia          17.4     211       60 25.8
## Hawaii            5.3      46       83 20.2
## Idaho             2.6     120       54 14.2
## Illinois         10.4     249       83 24.0
## Indiana           7.2     113       65 21.0
## Iowa              2.2      56       57 11.3
## Kansas            6.0     115       66 18.0
## Kentucky          9.7     109       52 16.3
## Louisiana        15.4     249       66 22.2
## Maine             2.1      83       51  7.8
## Maryland         11.3     300       67 27.8
## Massachusetts     4.4     149       85 16.3
## Michigan         12.1     255       74 35.1
## Minnesota         2.7      72       66 14.9
## Mississippi      16.1     259       44 17.1
## Missouri          9.0     178       70 28.2
## Montana           6.0     109       53 16.4
## Nebraska          4.3     102       62 16.5
## Nevada           12.2     252       81 46.0
## New Hampshire     2.1      57       56  9.5
## New Jersey        7.4     159       89 18.8
## New Mexico       11.4     285       70 32.1
## New York         11.1     254       86 26.1
## North Carolina   13.0     337       45 16.1
## North Dakota      0.8      45       44  7.3
## Ohio              7.3     120       75 21.4
## Oklahoma          6.6     151       68 20.0
## Oregon            4.9     159       67 29.3
## Pennsylvania      6.3     106       72 14.9
## Rhode Island      3.4     174       87  8.3
## South Carolina   14.4     279       48 22.5
## South Dakota      3.8      86       45 12.8
## Tennessee        13.2     188       59 26.9
## Texas            12.7     201       80 25.5
## Utah              3.2     120       80 22.9
## Vermont           2.2      48       32 11.2
## Virginia          8.5     156       63 20.7
## Washington        4.0     145       73 26.2
## West Virginia     5.7      81       39  9.3
## Wisconsin         2.6      53       66 10.8
## Wyoming           6.8     161       60 15.6</code></pre>
<p>Load the USArrests dataset and rename it <code>dat</code>. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</p>
<p>Answer: It’s useful to rename the dataset so that we know specifically which dataset we are working with. Additionally, when we edit the dataset it is helpful to have a differentiation (in name) from the original dataset. Additionally “dat” is shorter than the original dataset name.</p>
</div>
<div id="problem-2" class="section level3">
<h3>Problem 2</h3>
<p>Use this command to make the state names into a new variable called State.</p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))
names(dat)
# This line creates a new variable: states</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p>List the variables contained in the dataset <code>USArrests</code>. Answer: The variables are murder, assault, urbanpop, and rape.</p>
</div>
<div id="problem-3" class="section level3">
<h3>Problem 3</h3>
<p>What type of variable (from the DVB chapter) is <code>Murder</code>?</p>
<p>Answer: According to the DVB chapter, murder is a quantitative variable.</p>
<p>What R Type of variable is it?</p>
<p>Answer:In R, Murder is a character variable.</p>
</div>
<div id="problem-4" class="section level3">
<h3>Problem 4</h3>
<p>What information is contained in this dataset, in general? What do the numbers mean?</p>
<p>Answer: This dataset lists the average rate of arrests in each state for a specific type of crime. For example, in Iowa there has been an average of 2.2 arrests for murder. The fact that some of the data are listed as decimal numbers indicates that the dataset is reporting averages, as there cannot actually be 2.2 real arrests.</p>
</div>
<div id="problem-5" class="section level3">
<h3>Problem 5</h3>
<p>Draw a histogram of <code>Murder</code> with proper labels and title.</p>
<pre class="r"><code>hist(dat$Murder, main=&quot;US Arrests for Murder&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;) # This line contains the code for the histogram, including its title and axis names</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="problem-6" class="section level3">
<h3>Problem 6</h3>
<p>Please summarize <code>Murder</code> quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</p>
<p>Answer: Murder’s mean is 7.788. Its median is 7.25. The mean is the average of all values in the dataset, whereas the median is simply the middle value of those listed from smallest to largest. The median is also synonymous with the second quartile, Q2. A quartile is when the values of a dataset are divided into four groups. R gives the first and third quartiles because these are common values used in statistics, so it is helpful for R to calculate them automatically.</p>
<pre class="r"><code>a&lt;-c(13.2, 10.0, 8.1, 8.8, 9.0, 7.9, 3.3, 5.9, 15.4, 17.4, 5.3, 2.6, 10.4, 7.2, 2.2, 6.0, 9.7, 15.4, 2.1, 11.3, 4.4, 12.1, 2.7, 16.1, 9.0, 6.0, 4.3, 12.2, 2.1, 7.4, 11.4, 11.1, 13.0, 0.8, 7.3, 6.6, 4.9, 6.3, 3.4, 14.4, 3.8, 13.2, 12.7, 3.2, 2.2, 8.5, 4.0, 5.7, 2.6, 6.8) # This line creates the label &quot;a&quot; for the set of data values in Murder. 
mean(a) # This code calculates the mean of a. </code></pre>
<pre><code>## [1] 7.788</code></pre>
<pre class="r"><code>median(a) # This code calculates the median of a. </code></pre>
<pre><code>## [1] 7.25</code></pre>
</div>
<div id="problem-7" class="section level3">
<h3>Problem 7</h3>
<p>Repeat the same steps you followed for <code>Murder</code>, for the variables <code>Assault</code> and <code>Rape</code>. Now plot all three histograms together. You can do this by using the command <code>par(mfrow=c(3,1))</code> and then plotting each of the three.</p>
<pre class="r"><code>b&lt;-c(236, 263, 294, 190, 276, 204, 110, 238, 335, 211, 46, 120, 249, 113, 56, 115, 109, 249, 83, 300, 149, 255, 72, 259, 178, 109, 102, 252, 57, 159, 285, 254, 337, 45, 120, 151, 159, 106, 174, 279, 86, 188, 201, 120, 48, 156, 145, 81, 53, 161) # creates the label &quot;b&quot; for the set of data values in Assault
mean(b) # calculates the mean of Assault</code></pre>
<pre><code>## [1] 170.76</code></pre>
<pre class="r"><code>median(b) # calculates the median of Assault</code></pre>
<pre><code>## [1] 159</code></pre>
<pre class="r"><code>b&lt;-c(236, 263, 294, 190, 276, 204, 110, 238, 335, 211, 46, 120, 249, 113, 56, 115, 109, 249, 83, 300, 149, 255, 72, 259, 178, 109, 102, 252, 57, 159, 285, 254, 337, 45, 120, 151, 159, 106, 174, 279, 86, 188, 201, 120, 48, 156, 145, 81, 53, 161) # creates the label &quot;c&quot; for the set of data values in Rape
mean(b) # calculates the mean of Rape</code></pre>
<pre><code>## [1] 170.76</code></pre>
<pre class="r"><code>median(b) # calculates the median of Rape</code></pre>
<pre><code>## [1] 159</code></pre>
<pre class="r"><code>hist(dat$Assault, main=&quot;US Arrests for Assault&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;) # Code for histogram of Assault, including title and axis labels</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-1.png" width="480" /></p>
<pre class="r"><code>hist(dat$Rape, main=&quot;US Arrests for Rape&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;) # Code for histogram of Rape, including title and axis labels</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-2.png" width="480" /></p>
<pre class="r"><code>par(&quot;mar&quot;)</code></pre>
<pre><code>## [1] 5.1 4.1 4.1 2.1</code></pre>
<pre class="r"><code>par(mar=c(1,1,1,1)) # command to fix the parameters to fix the fact that the figure margins were too large
par(mfrow=c(3,1)) # command to plot multiple histograms
hist(dat$Murder, main=&quot;US Arrests for Murder&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;)
hist(dat$Assault, main=&quot;US Arrests for Assault&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;)
hist(dat$Rape, main=&quot;US Arrests for Rape&quot;, xlab=&quot;Average Arrests&quot;, ylab=&quot;Frequency of Average Arrests&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-3.png" width="480" /> Answer: The mean of Assault is 170.76 and the median is 159. The mean of Rape is 21.232 and the median is 20.1.</p>
<p>What does the command par do, in your own words (you can look this up by asking R <code>?par</code>)?</p>
<p>Answer: The command par allows you to set parameters when graphing, or to simply look up certain graphical parameters.</p>
<p>What can you learn from plotting the histograms together?</p>
<p>Answer:By plotting the histograms together, it becomes easier to see how the rates of arrests compare for the type of crimes committed. For example, it is evident from looking at the histograms that the rate of arrests for assault is much higher than that of murder. It is a helpful way to learn how the difrferent variables interact.</p>
</div>
<div id="problem-8" class="section level3">
<h3>Problem 8</h3>
<p>In the console below (not in text), type <code>install.packages("maps")</code> and press Enter, and then type <code>install.packages("ggplot2")</code> and press Enter. This will install the packages so you can load the libraries.</p>
</div>
</div>
<div id="assignment-2" class="section level1">
<h1>Assignment 2</h1>
<div id="crim-250-statistics-for-the-social-sciences" class="section level2">
<h2>Crim 250: Statistics for the Social Sciences</h2>
<p>Name: Elizabeth Stoner Date: 09/27/2021</p>
<div id="instructions-copy-your-code-paste-it-into-a-word-document-and-turn-it-into-canvas.-you-can-turn-in-a-.docx-or-.pdf-file.-show-any-eda-graphical-or-non-graphical-you-have-used-to-come-to-this-conclusion." class="section level3">
<h3>Instructions: Copy your code, paste it into a Word document, and turn it into Canvas. You can turn in a .docx or .pdf file. Show any EDA (graphical or non-graphical) you have used to come to this conclusion.</h3>
</div>
<div id="problem-1-load-data" class="section level3">
<h3>Problem 1: Load data</h3>
<p>Set your working directory to the folder where you downloaded the data. setwd(“C:/Users/Elizabeth/Desktop/CRIM 250”)</p>
<p>Read the data</p>
<pre class="r"><code>#Sys.which(&quot;make&quot;)
## &quot;C:\\rtools40\\usr\\bin\\make.exe&quot;
#install.packages(&quot;jsonlite&quot;, type = &quot;source&quot;)
#install.packages(&#39;plyr&#39;, repos = &quot;http://cran.us.r-project.org&quot;)</code></pre>
<pre class="r"><code>library(readr)
dat_nsduh_small_1 &lt;- read_csv(&quot;dat.nsduh.small.1.csv&quot;)
dat &lt;- read_csv(&quot;dat.nsduh.small.1.csv&quot;)</code></pre>
<p>What are the dimensions of the dataset? dim(dat) The dimensions of the dataset are 171 observations of 7 variables.</p>
<p>names(dat) The names of the variables are mjage, cigage, iralcage, age2, sexatract, speakengl, and irsex.</p>
</div>
<div id="problem-2-variables" class="section level3">
<h3>Problem 2: Variables</h3>
<p>Describe the variables in the dataset. class(dat<span class="math inline">\(mjage) class(dat\)</span>cigage) class(dat<span class="math inline">\(iralcage) class(dat\)</span>age2) class(dat<span class="math inline">\(sexatract) class(dat\)</span>speakengl) class(dat$irsex) There are seven variables in the dataset. In R, each variable is numeric. Mjage stands for the age at which respondents used marijuana or hashish for the first time. Cigage shows the ages at which respondents first started smoking cigarettes every day. Iralcage is the ages at which respondents first tried alcohol. Age2 is the most recent age of the respondents. Irsex is the gender of the respondents and is a categorical variable. Sexatract lists the sexual attraction of the respondents. Speakengl lists how well the respondents speak English.</p>
<p>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data? The dataset is from the National Survey of Drug Use and Health. The dataset is used to understand the extent of drug use and other health issues throughout the United States. The data were collected by the Substance Abuse and Mental Health Services Administration, part of the U.S. Department of Health and Human Services. The NSDUH uses a stratified sample within the United States population. The purpose of gathering this data is to provide an understanding of the health issues pervasive in America in order to establish helpful treatment programs and inform public policy.</p>
</div>
<div id="problem-3-age-and-gender" class="section level3">
<h3>Problem 3: Age and gender</h3>
<p>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.</p>
<pre class="r"><code>hist(dat$age2,
     main=&quot;Final Age&quot;,
     xlab=&quot;Age Response Code&quot;,
     ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The majority of the age variables were listed between 12 and 16. According to the codebook, this indicates that most respondents were between 24 and 64 years old. The most frequent ages reported were from 30 to 64 years old. The least frequent ages reported were between 15 to 19 years old. In this dataset there were no ages younger than 15.</p>
<p>Do you think this age distribution is representative of the US population? Why or why not? I would expect to see a higher frequency of 18 to 30 year olds, rather than have the peak start at 30. Additionally, according to the codebook, the ages of respondents when the questionnaire began were different from when it ended. As a result, I expect that this distribution is not entirely reflective of the age distribution of the current U.S. population; however, it is likely not too skewed either.</p>
<p>Is the sample balanced in terms of gender? If not, are there more females or males?</p>
<pre class="r"><code>table(dat$irsex)</code></pre>
<pre><code>## 
##  1  2 
## 91 80</code></pre>
<p>According to the table generated by R, there are 91 males and 80 females in the dataset. Therefore, it is not balanced as there are more males than females.</p>
<p>Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?</p>
<pre class="r"><code>tab.agesex &lt;- table(dat$irsex, dat$age2)
barplot(tab.agesex,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Age category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>This plot shows, as would be expected, that there were more men in each age group, aside from ages 19 to 20, than women who participated. However, the most frequent age range of both males and females was ages 35 to 49. It is also worth noting that the only participants ages 16 to 17 were male. It is at these younger ages that we see more discrepancies between male and female participants. But starting at age 21, the male-female distribution evens out a bit.</p>
</div>
<div id="problem-4-substance-use" class="section level3">
<h3>Problem 4: Substance use</h3>
<p>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?</p>
<pre class="r"><code>par(&quot;mar&quot;)</code></pre>
<pre><code>## [1] 5.1 4.1 4.1 2.1</code></pre>
<pre class="r"><code>par(mar=c(1,1,1,1))
par(mfrow=c(3,1))
hist(dat$mjage, main=&quot;First use Marijuana&quot;, xlab=&quot;Age&quot;, ylab=&quot;Frequency of Age&quot;)
hist(dat$cigage, main=&quot;First smoked Cigarettes&quot;, xlab=&quot;Age&quot;, ylab=&quot;Frequency of Age&quot;)
hist(dat$iralcage, main=&quot;First tried Alcohol&quot;, xlab=&quot;Age&quot;, ylab=&quot;Frequency of Age&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Based on the histograms, individuals tend to use alcohol earlier. It had the most frequent values of ages 5 to 10 compared to marijuana and cigarettes.</p>
</div>
<div id="problem-5-sexual-attraction" class="section level3">
<h3>Problem 5: Sexual attraction</h3>
<p>What does the distribution of sexual attraction look like? Is this what you expected?</p>
<pre class="r"><code>#install.packages(&quot;magrittr&quot;) # package installations are only needed the first time you use it
#install.packages(&quot;dplyr&quot;)    # alternative installation of the %&gt;%
library(magrittr) # needs to be run every time you start R and want to use %&gt;%
library(dplyr)    # alternatively, this also loads %&gt;%
dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;99&quot;)
hist(dat$sexatract, main=&quot;Sexual Attraction&quot;, xlab=&quot;Attraction&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>After removing the outlying values of 99, which indicates a skip of data, the histogram peaks at a value of 1. This means that the majority of respondents reported that they are only attracted to the opposite sex. Very few respondents answered that they were attracted, or mostly attracted, to the same sex. At least one respondent reported that they were unsure. I would have expected more variation in attraction with higher frequencies of people attracted to the same sex. This could be explained by the fact that the sample size is relatively small, and therefore may not be entirely representative of the U.S. population in terms of sexual attraction.</p>
<p>What is the distribution of sexual attraction by gender?</p>
<pre class="r"><code>tab.sexatract &lt;- table(dat$irsex, dat$sexatract)
barplot(tab.sexatract,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Attraction category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.sexatract),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>According to the barchart more males than females reported that they were only attracted to the opposite sex. Additionally, the majority of males and females reported that they were only attracted to the opposite sex. More females than males reported that they were mostly attracted to the opposite sex or were equally attracted to both sexes. More males than females reported that they were mostly or only attracted to members of the same sex. Additionally, the respondent who reported they were unsure was male.</p>
</div>
<div id="problem-6-english-speaking" class="section level3">
<h3>Problem 6: English speaking</h3>
<p>What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population?</p>
<pre class="r"><code>hist(dat$speakengl, main=&quot;Speak English&quot;, xlab=&quot;How well&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Most of the respondents, over 150, reported that they speak English very well, with few simply answering well, and even fewer reporting that they do not speak it well. In a random sample of the U.S. population, I would expect that more people would answer that they do not speak English very well, creating more variation in the histogram. Due to the large number of immigrants from all over the world it would make sense for more people within the whole population to not feel as confident in their English speaking.</p>
<p>Are there more English speaker females or males?</p>
<pre class="r"><code>tab.sexengl &lt;- table(dat$irsex, dat$speakengl)
barplot(tab.sexengl,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;English category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.sexengl),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>According to the barchart, those who speak English very well are almost evenly distributed between males and females. However, more males than females reported that they speak English well, indicating that overall, more males than females speak English within the sample. Additionally, more females than males reported that they do not speak English well.</p>
</div>
</div>
</div>
<div id="exam-1" class="section level1">
<h1>Exam 1</h1>
<div id="elizabeth-stoner" class="section level2">
<h2>Elizabeth Stoner</h2>
</div>
<div id="section" class="section level2">
<h2>10/04/2021</h2>
<p>output: html_document</p>
<div id="instructions" class="section level3">
<h3>Instructions</h3>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.</p></li>
<li><p>Download the README.md file. This is the codebook.</p></li>
<li><p>Load the data into an R data frame.</p></li>
</ol>
<pre class="r"><code>library(readr)
fatal_police_shootings_data &lt;- dat&lt;-read_csv(&quot;fatal-police-shootings-data.csv&quot;)</code></pre>
</div>
<div id="problem-1-10-points" class="section level3">
<h3>Problem 1 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</li>
</ol>
<p><strong>The dataset describes information about fatal police shootings in the US from 2015 to 2021. There are 6594 subjects included in teh dataset.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many observations are there in the data frame?</li>
</ol>
<pre class="r"><code>names(dat) #Lists the names of all the variables in dat</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
<p><strong>There are 17 categories used to observe 6594 individuals, so 6594 observations.</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</li>
</ol>
<p><strong>“Body camera” means whether news reports indicated that the officer was wearing a body camera at the time of the incident, which may have recorded some of the events. “Flee” means whether news reports said that the subject was moving away from the officer. “Armed” indicates whether the subject was armed with some sort of object that the officer believed could have caused harm.</strong></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</li>
</ol>
<pre class="r"><code>table(dat$armed)</code></pre>
<pre><code>## 
##                  air conditioner                       air pistol 
##                                1                                1 
##                   Airsoft pistol                               ax 
##                                3                               24 
##                         barstool                     baseball bat 
##                                1                               20 
##          baseball bat and bottle baseball bat and fireplace poker 
##                                1                                1 
##           baseball bat and knife                            baton 
##                                1                                6 
##                           BB gun               BB gun and vehicle 
##                               15                                1 
##                     bean-bag gun                      beer bottle 
##                                1                                3 
##                       binoculars                     blunt object 
##                                1                                5 
##                           bottle                    bow and arrow 
##                                1                                1 
##                       box cutter                            brick 
##                               13                                2 
##              car, knife and mace                          carjack 
##                                1                                1 
##                            chain                        chain saw 
##                                3                                2 
##                         chainsaw                            chair 
##                                1                                4 
##              claimed to be armed               contractor&#39;s level 
##                                1                                1 
##                   cordless drill                         crossbow 
##                                1                                9 
##                          crowbar                        fireworks 
##                                5                                1 
##                         flagpole                       flashlight 
##                                1                                2 
##                      garden tool                      glass shard 
##                                2                                4 
##                          grenade                              gun 
##                                1                             3798 
##                      gun and car                    gun and knife 
##                               12                               22 
##                  gun and machete                    gun and sword 
##                                3                                1 
##                  gun and vehicle              guns and explosives 
##                               17                                3 
##                           hammer                       hand torch 
##                               18                                1 
##                          hatchet                  hatchet and gun 
##                               14                                2 
##                         ice pick                incendiary device 
##                                1                                2 
##                            knife                knife and vehicle 
##                              955                                1 
##                 lawn mower blade                          machete 
##                                2                               51 
##                  machete and gun                     meat cleaver 
##                                1                                6 
##                  metal hand tool                     metal object 
##                                2                                5 
##                       metal pipe                       metal pole 
##                               16                                4 
##                       metal rake                      metal stick 
##                                1                                3 
##                       microphone                       motorcycle 
##                                1                                1 
##                         nail gun                              oar 
##                                1                                1 
##                       pellet gun                              pen 
##                                3                                1 
##                     pepper spray                         pick-axe 
##                                2                                4 
##                    piece of wood                             pipe 
##                                7                                7 
##                        pitchfork                             pole 
##                                2                                3 
##                   pole and knife                  railroad spikes 
##                                2                                1 
##                             rock                    samurai sword 
##                                7                                4 
##                         scissors                      screwdriver 
##                                9                               16 
##                     sharp object                           shovel 
##                               14                                7 
##                            spear                          stapler 
##                                2                                1 
##              straight edge razor                            sword 
##                                5                               23 
##                            Taser                        tire iron 
##                               34                                4 
##                       toy weapon                          unarmed 
##                              226                              421 
##                     undetermined                   unknown weapon 
##                              188                               82 
##                          vehicle                  vehicle and gun 
##                              213                                8 
##              vehicle and machete                    walking stick 
##                                1                                1 
##                       wasp spray                           wrench 
##                                1                                1</code></pre>
<p><strong>I find it most surprising to see an air conditioner, wasp spray, and a microphone in the “armed” variable.</strong></p>
</div>
<div id="problem-2-10-points" class="section level3">
<h3>Problem 2 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the age distribution of the sample. Is this what you would expect to see?</li>
</ol>
<pre class="r"><code>hist(dat$age, main=&quot;Age&quot;, xlab=&quot;Subject Age&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p><strong>There seems to be a higher frequency of ages 20 to 40, so the plot has a right skew. It makes sense that people from these age ranges may be more likely to be involved in police incidents. They are able to be more active, unlike many in their eighties. There is a rather steady decline starting from age 40 going to 80 in the ages of those involved in fatal police shootings. This is also what I would expect. The older people get, the less likely they are to engage in criminal activities, or activities that could be mistaken for criminal activities. Older people may also seem less threatening, so officers may be less inclined to use deadly force on them.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</li>
</ol>
<pre class="r"><code>summary(dat$age)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    6.00   27.00   35.00   37.12   45.00   91.00     308</code></pre>
<p><strong>To find the center of a distribution it is best to use the median, which is the middle value of a dataset. For this age distribution the median is 35.</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the gender distribution of the sample. Do you find this surprising?</li>
</ol>
<pre class="r"><code>table(dat$gender)</code></pre>
<pre><code>## 
##    F    M 
##  293 6298</code></pre>
<pre class="r"><code>barplot(table(dat$gender), main=&quot;Gender&quot;) #Organizing the data into a barplot to visualize the distribution</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>There are 6298 males and 293 females in the dataset. While I would expect there to be more males than females, I am very surprised that there are over twenty times more males than females involved in fatal police shootings.</strong></p>
</div>
<div id="problem-3-10-points" class="section level3">
<h3>Problem 3 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</li>
</ol>
<pre class="r"><code>table(dat$body_camera)</code></pre>
<pre><code>## 
## FALSE  TRUE 
##  5684   910</code></pre>
<p><strong>According to news reports only 910 officers had a body camera to capture parts of the incidents. This is less than one sixth of all of the incidents in the data. I am quite surprised at how low it is. I would also expect that in recent years there would be a greater increase in body camera use; however, looking at the dataset that does not seem to be the case.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</li>
</ol>
<pre class="r"><code>table(dat$flee)</code></pre>
<pre><code>## 
##         Car        Foot Not fleeing       Other 
##        1058         845        3952         248</code></pre>
<p><strong>The victim fled via car in 1058 incidents and on foot in 845 incidents.So, there were 1903 cases in which the victim fled. There is also an other category applied to 248 cases. However, this category could simply be missing values or other occurrences that are difficult to classify as either fleeing or not fleeing. In 3925 cases the victim was not fleeing. This is about 60% of the cases. I would expect more victims to flee so that there was a more even distribution. However, I suppose it might make sense for officers to interpret victims standing their ground to be more threatening than those trying to run away.</strong></p>
</div>
<div id="problem-4-10-points---answer-only-one-of-these-a-or-b." class="section level3">
<h3>Problem 4 (10 points) - Answer only one of these (a or b).</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>tab.bodycameraflee&lt;-table(dat$body_camera, dat$flee) #Making a table for both variables
barplot(tab.bodycameraflee, main=&quot;Body Camera-Flee Relationship&quot;, xlab=&quot;Flee&quot;, ylab=&quot;Body Camera Frequency&quot;, legend.text=rownames(tab.bodycameraflee),
        beside = FALSE) #Stacked barplot code using the tables</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p><strong>From looking at the barplot it is clear that in the majority of cases the officers were not reported to have body cameras. For the cases in which the victims fled, very few officers were reported to have body cameras. The officers were reported to have body cameras mostly when the victims were not fleeing. As this is the largest category, it makes sense that it would also happen to have the most instances of officers having body cameras. This barplot might suggest that when the victims fled, officers perhaps turned off or removed their body cameras. Or the footage could be obstructed due to the action. It makes sense that it is easiest to capture footage of a victim who is stationary. However, the data does not explain the staggering lack of body camera use in all of the categories. Even in the not fleeing category very few officers were reported to have body cameras. It should also be noted that the Other category is likely missing data about whether the victim fled or not. </strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<p><strong>Your answer here.</strong></p>
</div>
<div id="extra-credit-10-points" class="section level3">
<h3>Extra credit (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>What does this code tell us?</li>
</ol>
<pre class="r"><code>mydates &lt;- as.Date(dat$date) #renames the date category as &quot;mydates&quot;
head(mydates) #finds the first part of the vector mydates
(mydates[length(mydates)] - mydates[1]) #sets the length of the vector list for mydates</code></pre>
<p><strong>This code tells us about the values in the vector list renamed to “mydates”.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported? <strong>It would be easy to mislabel police killings due to the lack of body cameras worn by officers, which could provide helpful information to understand the facts of teh case. Instead, it is likely a “he-said-she-said” situation in which bystanders and families of the victims feel that their word will not be taken seriously.</strong></p></li>
<li><p>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data? <strong>There are around 248 missing values listed as “other” in the flee category. However, it is likely that there is more that could be missing from the data. For example, looking at the dataset shows missing data in the armed category</strong></p></li>
</ol>
</div>
</div>
</div>
<div id="assignment-3" class="section level1">
<h1>Assignment 3</h1>
<div id="elizabeth-stoner-1" class="section level2">
<h2>Elizabeth Stoner</h2>
</div>
<div id="section-1" class="section level2">
<h2>10/23/2021</h2>
<p>output: pdf_document: default html_document: default</p>
<p><strong>Collaborators: Carmen Avery and Halle Wasser</strong>.</p>
<p>This assignment is due on Canvas on Wednesday 10/27/2021 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<p>Submit your responses as either an HTML file or a PDF file on Canvas. Also, please upload it to your website.</p>
<p>Save the file (found on Canvas) crime_simple.txt to the same folder as this file (your Rmd file for Assignment 3).</p>
<p>Load the data.</p>
<pre class="r"><code>library(readr)
library(knitr)
dat.crime &lt;- read_delim(&quot;crime_simple.txt&quot;, delim=&quot;\t&quot;)</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<div id="how-many-observations-are-there-in-the-dataset-to-what-does-each-observation-correspond" class="section level3">
<h3>1. How many observations are there in the dataset? To what does each observation correspond?</h3>
<pre class="r"><code>summary(dat.crime)</code></pre>
<pre><code>##        R               Age              S                Ed       
##  Min.   : 34.20   Min.   :119.0   Min.   :0.0000   Min.   : 87.0  
##  1st Qu.: 65.85   1st Qu.:130.0   1st Qu.:0.0000   1st Qu.: 97.5  
##  Median : 83.10   Median :136.0   Median :0.0000   Median :108.0  
##  Mean   : 90.51   Mean   :138.6   Mean   :0.3404   Mean   :105.6  
##  3rd Qu.:105.75   3rd Qu.:146.0   3rd Qu.:1.0000   3rd Qu.:114.5  
##  Max.   :199.30   Max.   :177.0   Max.   :1.0000   Max.   :122.0  
##       Ex0             Ex1               LF              M         
##  Min.   : 45.0   Min.   : 41.00   Min.   :480.0   Min.   : 934.0  
##  1st Qu.: 62.5   1st Qu.: 58.50   1st Qu.:530.5   1st Qu.: 964.5  
##  Median : 78.0   Median : 73.00   Median :560.0   Median : 977.0  
##  Mean   : 85.0   Mean   : 80.23   Mean   :561.2   Mean   : 983.0  
##  3rd Qu.:104.5   3rd Qu.: 97.00   3rd Qu.:593.0   3rd Qu.: 992.0  
##  Max.   :166.0   Max.   :157.00   Max.   :641.0   Max.   :1071.0  
##        N                NW              U1               U2       
##  Min.   :  3.00   Min.   :  2.0   Min.   : 70.00   Min.   :20.00  
##  1st Qu.: 10.00   1st Qu.: 24.0   1st Qu.: 80.50   1st Qu.:27.50  
##  Median : 25.00   Median : 76.0   Median : 92.00   Median :34.00  
##  Mean   : 36.62   Mean   :101.1   Mean   : 95.47   Mean   :33.98  
##  3rd Qu.: 41.50   3rd Qu.:132.5   3rd Qu.:104.00   3rd Qu.:38.50  
##  Max.   :168.00   Max.   :423.0   Max.   :142.00   Max.   :58.00  
##        W               X        
##  Min.   :288.0   Min.   :126.0  
##  1st Qu.:459.5   1st Qu.:165.5  
##  Median :537.0   Median :176.0  
##  Mean   :525.4   Mean   :194.0  
##  3rd Qu.:591.5   3rd Qu.:227.5  
##  Max.   :689.0   Max.   :276.0</code></pre>
<p><strong>There are 47 observations in the dataset, which correspond to 47 of the USA states and their 1960 crime data. There are 14 columns of variables providing information for each observation.</strong></p>
</div>
<div id="draw-a-scatterplot-of-the-two-variables.-calculate-the-correlation-between-the-two-variables.-can-you-come-up-with-an-explanation-for-this-relationship" class="section level3">
<h3>2. Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</h3>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between Average Education and Crime Rate for 47 States&quot;, xlab=&quot;Average Education&quot;, ylab=&quot;Crime Rate&quot;, cex.main=1)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-32-1.png" width="576" /></p>
<pre class="r"><code>cor(dat.crime$Ed, dat.crime$R)</code></pre>
<pre><code>## [1] 0.3228349</code></pre>
<p><strong>The correlation between the two variables is 0.3228349, which is a positive correlation. According to the codebook, R, the crime rate, is the number of offenses reported to police per million population, and Ed is the average years of schooling multiplied by ten for people of 25 years or older. So, as the average amount of schooling increases, so does the crime rate. A possible explanation for this relationship is that areas where people have higher levels of education may be better targets for those committing crimes. Education level is often correlated with better jobs and financial success, so perhaps areas with these people may be home to more criminal activity. Also, because R is specifically number of crimes reported, then maybe people with higher education levels are also more likely to report crimes to the police; however, this hypothesis cannot be proven by this data alone.</strong></p>
</div>
<div id="regress-reported-crime-rate-y-on-average-education-x-and-call-this-linear-model-crime.lm-and-write-the-summary-of-the-regression-by-using-this-code-which-makes-it-look-a-little-nicer-r-evalfalse-kablesummarycrime.lmcoef-digits-2." class="section level3">
<h3>3. Regress reported crime rate (y) on average education (x) and call this linear model <code>crime.lm</code> and write the summary of the regression by using this code, which makes it look a little nicer <code>{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)</code>.</h3>
<pre class="r"><code>#install.packages(&quot;kableExtra&quot;)
crime.lm &lt;- lm(formula=R~Ed, data=dat.crime)
# Remember to remove eval=FALSE above!
summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = R ~ Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -27.3967    51.8104  -0.529   0.5996  
## Ed            1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
</div>
<div id="are-the-four-assumptions-of-linear-regression-satisfied-to-answer-this-draw-the-relevant-plots.-write-a-maximum-of-one-sentence-per-assumption." class="section level3">
<h3>4. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</h3>
<pre class="r"><code>plot(dat.crime$Ed, crime.lm$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Education&quot;, ylab=&quot;Residuals&quot;) #Visualizing the data</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=1) #Plot for the linearity assumption and independence assumption</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p><strong>Based on the plot, the linearity assumption does not look to be met as the red line appears to have a varying pattern that is non-linear. The same can be said for the independence assumption; there is some sort of pattern, so the independence assumption is not met as well as we would like it to be.</strong></p>
<pre class="r"><code>plot(crime.lm, which=3) #Plot to test for the equal variance assumption </code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p><strong>Using the scale-location plot, it appears as though the data does not perfectly satisfy the equal variance assumption as the line curves upward then decreases around the x-value of 100, and the distribution of the data points increase around the middle but is thinner near the beginning, suggesting a lack of homoscedasticity.</strong></p>
<pre class="r"><code>plot(crime.lm, which=2) #Plot to test the normal population assumption</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p><strong>Based on the normal qq plot there are issues with the normal population assumption, as the plot is light tailed on both ends, meaning that those data points could be outliers, which no longer follow the slope of the line.</strong></p>
</div>
<div id="is-the-relationship-between-reported-crime-and-average-education-statistically-significant-report-the-estimated-coefficient-of-the-slope-the-standard-error-and-the-p-value.-what-does-it-mean-for-the-relationship-to-be-statistically-significant" class="section level3">
<h3>5. Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</h3>
<p><strong>The estimated coefficient of the slope is 1.1161, which indicates the effect that education has on the reported crime rate. The standard error is 0.4878, which indicates the potential variance of crimes actually reported. The p-value is 0.0269 for the slope, which indicates that there is only a weak relationship between reported crime and average education. This means that the relationship is not statistically significant. A statistically significant relationship would be such that the relationship is unlikely to occur randomly, or unlikely to occur given the null hypothesis. Therefore, this relationship is more likely to have occurred due to randomness or some other factor.</strong></p>
</div>
<div id="how-are-reported-crime-and-average-education-related-in-other-words-for-every-unit-increase-in-average-education-how-does-reported-crime-rate-change-per-million-per-state" class="section level3">
<h3>6. How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</h3>
<p><strong>Based on the data, for every increase in one unit of average education, number of offenses reported to the police increases by 1.1161 per million per state.</strong></p>
</div>
<div id="can-you-conclude-that-if-individuals-were-to-receive-more-education-then-crime-will-be-reported-more-often-why-or-why-not" class="section level3">
<h3>7. Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</h3>
<p><strong>Using the data provided we cannot conclude that if individuals were to receive more education, then crime would be reported more often. The statistical relationship is weak, at best. And, even so, that relationship does not automatically indicate causality. There could be other factors that have yet to be measured that could influence the perceived relationship. For example, community relations with local law enforcement is an important factor in a willingness to report crimes, but is not observably related to education levels. So, in order to infer any further relationship, more information and more data are needed.</strong></p>
</div>
</div>
</div>
<div id="exam-2" class="section level1">
<h1>Exam 2</h1>
<div id="elizabeth-stoner-2" class="section level2">
<h2>Elizabeth Stoner</h2>
</div>
<div id="section-2" class="section level2">
<h2>11/01/2021</h2>
<p>output: html_document</p>
<div id="instructions-1" class="section level3">
<h3>Instructions</h3>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p></li>
<li><p>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: <strong>“Does having more funding in a police department lead to fewer incidents of police brutality?”</strong></p></li>
<li><p>Codebook:</p></li>
</ol>
<ul>
<li>funds: How much funding the police department received in that year in millions of dollars.</li>
<li>po.brut: How many incidents of police brutality were reported by the department that year.</li>
<li>po.dept.code: Police department code</li>
</ul>
</div>
<div id="problem-1-eda-10-points" class="section level3">
<h3>Problem 1: EDA (10 points)</h3>
<p>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</p>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;sim.data.csv&#39;)
head(dat)</code></pre>
<pre><code>##   po.dept.code funds po.brut
## 1            1  48.1      23
## 2            2  81.4      10
## 3            3  41.8      25
## 4            4  61.7      19
## 5            5  86.4       8
## 6            6  51.6      22</code></pre>
<pre class="r"><code>class(dat$po.dept.code) #integer</code></pre>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<pre class="r"><code>class(dat$funds) #numeric</code></pre>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<pre class="r"><code>class(dat$po.brut) #integer</code></pre>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<p><strong>The dataset has 200 observations of police departments. For each observation the dataset has information about three variables. The variables include funds, meaning how much funding the police department received in millions of dollars for one specific year. It is a numeric variable. Another variable is po.brut, which is how many incidents of police brutality were reported by the department that year, which is an integer variable. The last variable is po.dept.code, which just means police department code, identifying which department it is. This variable is an integer. The scatter plot create seems to suggest that there may be a relationship between the two variables in question; however, more analysis is necessary to actually conclude this.</strong></p>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main=&quot;Scatterplot&quot;, xlab=&quot;Funds&quot;, ylab=&quot;Reported Police Brutality&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
</div>
<div id="problem-2-linear-regression-30-points" class="section level3">
<h3>Problem 2: Linear regression (30 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
reg.output &lt;- lm(formula=po.brut~funds, data=dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = po.brut ~ funds, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## funds       -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</li>
</ol>
<p><strong>The estimated coefficient of the slope term is -0.367099, which suggests that as funding increases by one unit of million dollars, there may be observed a decrease in reported police brutality by 0.367099. The standard error is 0.004496, meaning this is how much variation there might be for any predicted values. The p-value of the slope is &lt;2e-16. As indicated by the three asterisks this is very statistically significant, as it is less than 5% and close to zero.</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
plot(dat$funds, dat$po.brut, main=&quot;Scatterplot&quot;, xlab=&quot;x, po.brut&quot;, ylab=&quot;y, funds&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-42-1.png" width="384" /></p>
<p>Does the line look like a good fit? Why or why not?</p>
<p><strong>This line does look like a good fit. The data itself looks almost normally distributed, however it does appear to have a slight left skew. Nevertheless, the regression line looks to be a good fit, particularly in the middle of the data distribution.</strong></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</li>
</ol>
<pre class="r"><code>plot(reg.output, which=1) #Linearity and Independence assumptions</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p><strong>Using this plot the linearity assumption is not met as there is a clear curved pattern rather than a straight line. Based on this test we can also say that the independence assumption is not met either, because of this clear pattern. If I had more time I would transform the data. In order to figure out what type of transformation I should apply I would use the Box-Cox method, then create a new plot using the transformed data.</strong></p>
<pre class="r"><code>plot(reg.output, which=3) #Equal variance assumption</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p><strong>This plot does not meet the equal variance assumption as the data points are somewhat homoscedastic in the middle of the plot, but it gets much thinner on both ends. If I had more time I would follow the same steps as for the other assumptions to transform and re-analyze the data.</strong></p>
<pre class="r"><code>plot(reg.output, which=2) #Normal population assumption</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p><strong>Using the normal qq plot it appears that the data do not meet the normal population assumption since the plot exhibits a heavy left skew. As before, I would use the Box-Cox test to figure out how best to transform the data.</strong></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Answer the question of interest based on your analysis.</li>
</ol>
<p><strong>After this analysis I cannot immediately say that having more funding leads to fewer incidents of police brutality. As none of the assumptions were met, it would not be a good idea to use the linear regression to infer or predict any relationship between the variables. There is more analysis that should be done to fully understand how the variables do or do not relate to one another. Because the p-value suggested strong statistical significance this would be worth doing.</strong></p>
</div>
<div id="problem-3-data-ethics-10-points" class="section level3">
<h3>Problem 3: Data ethics (10 points)</h3>
<p>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</p>
<p><strong>Despite the fact that there are 200 observations, the dataset itself does not give us too much important information. Because the dataset is simulated we don’t know any sort of geographical or cultural information about these hypothetical police departments. If the police departments were to be all from around the same area or all from an urban setting, this would not be representative of the total population of police departments. If this were a real dataset I would also want to know if any police departments that were contacted for collecting data did not respond. If a specific department has a bad record for police brutality they may be less inclined to provide their information. Additionally, because the variable is reported police brutality, there are clearly cases of police brutality that go unreported. We do not have the ground truth. It is imperative to figure out, or at least estimate, how many these are. There should also be information based on community-police relations. If a community does not trust its police department then it is unlikely that they would report police brutality. Unfortunately, we can infer that the community may distrust their department specifically because of police brutality. Simply put, the nature of the variables is such that the cases that we care about are likely under reported. Because the dataset only has three variables, there could be a lot of other relationships that exist in reality that we have no way to measure using these three variables. I would also be concerned that someone performing linear regression on this dataset would be too quick to infer a causal relationship without testing the assumptions or performing transformations. This could lead to a lot of misinformation being spread about how to properly deal with police brutality.</strong></p>
</div>
</div>
</div>
<div id="assignment-4" class="section level1">
<h1>Assignment 4</h1>
<div id="elizabeth-stoner-3" class="section level2">
<h2>Elizabeth Stoner</h2>
</div>
<div id="section-3" class="section level2">
<h2>11/08/2021</h2>
<p>output: html_document: default</p>
<div id="data-visualisation" class="section level3">
<h3>Data Visualisation</h3>
<p>library(tidyverse) <strong>#loads the core tidyverse package, which helps access datasets, help pages, and functions</strong><br />
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── <strong>#list of packages loaded in with tidyverse</strong><br />
✔ ggplot2 3.3.2 ✔ purrr 0.3.4<br />
✔ tibble 3.0.3 ✔ dplyr 1.0.2<br />
✔ tidyr 1.1.2 ✔ stringr 1.4.0<br />
✔ readr 1.4.0 ✔ forcats 0.5.0<br />
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── <strong>#lists of any functions that might conflict with packages already loaded in R</strong><br />
✖ dplyr::filter() masks stats::filter()<br />
✖ dplyr::lag() masks stats::lag()</p>
<p>install.packages(“tidyverse”) <strong>#code to install tidyverse packages if not already installed. It only needs to be run once per session</strong><br />
library(tidyverse) <strong>#now it can load tidyverse</strong></p>
<p>mpg <strong>#loads a specific type of data frame from ggplot2. We can see here it has a rectangular set of variables (columns) and observations (rows). The loaded mpg dataset has observations from the US Environmental Protection Agency on 38 models of cars. The following rows listed show each observation within the dataset.</strong><br />
# A tibble: 234 x 11<br />
manufacturer model displ year cyl trans drv cty hwy fl class<br />
<chr> <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr><br />
1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compa…<br />
2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compa…<br />
3 audi a4 2 2008 4 manual(m6) f 20 31 p compa…<br />
4 audi a4 2 2008 4 auto(av) f 21 30 p compa…<br />
5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compa…<br />
6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compa…<br />
# … with 228 more rows</p>
<p>ggplot(data = mpg) + <strong>#Creates a plot of the dataset mpg. This first line specifically creates an empty graph with the data argument as mpg.</strong><br />
geom_point(mapping = aes(x = displ, y = hwy)) <strong>#The geom_point function adds a layer of points to the plot, creating a scatterplot. Mapping specifies that within the plot the variable displ will be on the x-axis and the variable hwy will be on the y-axis</strong></p>
<p>ggplot(data = <DATA>) + <strong>#Allows the code to become a reusable template for making grpahs through ggplot. Any of the bracketed sections can be replaced with actual data, geom-function, or mappings depending on the necessary template.</strong><br />
<GEOM_FUNCTION>(mapping = aes(<MAPPINGS>)) <strong>#Same function of making a template with the specified geom_function and mappings</strong></p>
<p>ggplot(data = mpg) + <strong>#mpg plot</strong><br />
geom_point(mapping = aes(x = displ, y = hwy, color = class)) <strong>#Maps the points on the plot with the specified axes like before, this time mapping the colors of the points to the class variable, which shows each class as a different color to visualize the distribution of class on the plot. The aes() funciton maps an aesthetic to a variable and assigns a level of the aesthetic to each variable value, which is called scaling. ggplot also provides a legend in the graph.</strong></p>
<p>ggplot(data = mpg) + <strong>#mpg plot</strong><br />
geom_point(mapping = aes(x = displ, y = hwy, size = class)) <strong>#This performs the same function as the earlier r chunk but this time instead of color the aesthetic assigned is size. Each type of class is assigned a different point size, and a legend is provided.</strong><br />
Warning: Using size for a discrete variable is not advised. <strong>#Warning that using size to map and visualize an unordered variable is a bad idea.</strong></p>
<p>Left plot<br />
ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy, alpha = class)) <strong>#Mapping class with the alpha aesthetic, which adjusts the transparency of points based on their class using the scaling process.</strong></p>
<p>Right plot<br />
ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy, shape = class)) <strong>#Mapping class with the shape aesthetic, which assigns a different shape as the point for each class value through scaling. Using the aes() function gathers each mapping from the layers and passes them tot he layer’s mapping argument. The function associates the specific aesthetic with the variable it is meant to display.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy), color = “blue”) <strong>#Sets the aesthetic properties of the geom_point manually, here making all of the plot points blue. This just changes the plot’s appearance. It doesn’t convey information about the plot. When setting the aesthetic manually it has to be coded outside of the aes() function. There are codes for different levels that can be used for setting the aesthetic.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy, color = “blue”)) <strong>#This code demonstrates what happens when the aesthetic is not coded properly and is instead inside the aes() function. On the plot the points are not blue, but are labeled blue. This code allows ggplot to pick a random color aesthetic for which each point is categorized in the variable “blue.”</strong></p>
<p>ggplot(data = mpg)<br />
+ geom_point(mapping = aes(x = displ, y = hwy)) <strong>#Faulty code in which the “+” was put at the beginning instead of the end of the line, which will produce an error message. If the error is unclear, the problem can be solved by getting help with the ?function_name command.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) <strong>#This line facets the plot, which displays one subset of the data. Here the use of “~ class” means that the plot is being faceted by one variable (class). The variable used in the facet_wrap() function needs to be discrete. Nrow=2 specifies that the plot should contain 2 rows.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) +<br />
facet_grid(drv ~ cyl) <strong>#This causes the plot to be faceted by 2 variables, which are separated by the ~. One of the two variables could also be replaced by a period to avoid faceting in the rows or columns dimension.</strong></p>
<p>ggplot(data = mpg) + <strong>#empty graph for plotting mpg dataset</strong><br />
geom_point(mapping = aes(x = drv, y = cyl)) <strong>#Adding the layer of points to the plot with an aesthetic applied to the variables drv and cyl. Since the aesthetic was not specified, ggplot will apply whichever aesthetic makes sense for the data. Also maps drv onto the x-axis and cyl onto the y-axis.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) + <strong>#Maps the same plot as earlier</strong><br />
facet_grid(drv ~ .) <strong>#Now a facet is applied, which displays drv, but does not facet cyl</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) +<br />
facet_grid(. ~ cyl) <strong>#The opposite is the case here so cyl is faceted but drv is not. Using this r chunk we get to see both faceted separately.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) + <strong>#Same plot that has been used</strong><br />
facet_wrap(~ class, nrow = 2) <strong>#This line facets the plot, which displays one subset of the data. Here the use of “~ class” means that the plot is being faceted by one variable (class). The variable used in the facet_wrap() function needs to be discrete. Nrow=2 specifies that the plot should contain 2 rows.</strong></p>
<p>left plot<br />
ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) <strong>#This code uses the point geom to create a normal scatterplot of the data. This maps the same plot as was used earlier with the variable displ on the x-axis and hwy on the y-axis.</strong></p>
<p>right plot<br />
ggplot(data = mpg) +<br />
geom_smooth(mapping = aes(x = displ, y = hwy)) <strong>#This code uses the smooth geom, which generates a smooth line fitted to the data.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv)) <strong>#Uses the geom_smooth function to generate a smooth line fitted to the data. Also includes the drv variable being mapped to linetype. So there will be a different line and linetype for each value of the variable set too linetype (in this case, the variable drv).</strong></p>
<p>ggplot(data = mpg) +<br />
geom_smooth(mapping = aes(x = displ, y = hwy)) <strong>#This code uses the smooth geom, which generates a smooth line fitted to the data.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_smooth(mapping = aes(x = displ, y = hwy, group = drv)) <strong>#Uses the geom_smooth function to generate a smooth line fitted to the data. Also includes the group aesthetic to drv, a categorical variable, to draw multiple objects. ggplot2 draws a separate object for each unique value of the grouping variable.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_smooth( <strong>#Uses the geom_smooth function to generate a smooth line fitted to the data.</strong><br />
mapping = aes(x = displ, y = hwy, color = drv),<br />
show.legend = FALSE<br />
) <strong>#Codes the color aesthetic to drv, a categorical variable, so that ggplot2 assigns a separate color for each unique value of the variable drv.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy)) +<br />
geom_smooth(mapping = aes(x = displ, y = hwy)) <strong>#Displays multiple geoms in the same plot by adding multiple geom functions to the same ggpplot</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + <strong>#This mapping function treats the set of mappings written here as global mappings that apply to each geom in the graph</strong><br />
geom_point() + <strong>#Produces scatterplot</strong><br />
geom_smooth() <strong>#Produces smooth line fitted to the data</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + <strong>#Mappings placed within the ggplot function are treated as global</strong> geom_point(mapping = aes(color = class)) + <strong>#Mappings placed within the geom function are treated as local for that specific layer, so that different aesthetics can be displayed in different layers. In this case the color aesthetic only applies to the scatterplot layer based on the class variable</strong><br />
geom_smooth()</p>
<p>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + <strong>#Mappings placed within the ggplot function are treated as global</strong><br />
geom_point(mapping = aes(color = class)) + <strong>#Mappings placed within the geom function are treated as local for that specific layer, so that different aesthetics can be displayed in different layers. In this case the color aesthetic only applies to the scatterplot layer based on the class variable</strong><br />
geom_smooth(data = filter(mpg, class == “subcompact”), se = FALSE) <strong>#Different data is being specified in the smooth geom. The line displays the new specified category of class “subcompact.” This only applies for this layer. se = FALSE means confidence interval is not shown around the line.</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + <strong>lobal mapping with the colors of the points depending on the drv variable.</strong><br />
geom_point() +<br />
geom_smooth(se = FALSE) <strong>#se argument shows the confidence interval around the line when applied to geom_smooth. When set to =FALSE it does not show this interval.</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + <strong>#This mapping function treats the set of mappings written here as global mappings that apply to each geom in the graph</strong><br />
geom_point() + <strong>#scatterplot</strong><br />
geom_smooth() <strong>#smooth line to fit data</strong></p>
<p>ggplot() +#ggplot does not have global mappings<br />
geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) +<br />
geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy)) <strong>#Here both geoms will display on the same plot. You would want to use a different code in the case that you want the axes to display different variables</strong></p>
<p>ggplot(data = diamonds) + #dataset used for ggplot now is diamonds<br />
geom_bar(mapping = aes(x = cut)) <strong>eom function used here creates a bar chart. The variable specified via mapping and the aesthetic is the cut, displayed on the x-axis. The y-axes not specified in the code is automatically set to display the frequency (or count) at which each cut category appears in the data. The program uses a stat to do this.</strong></p>
<p>ggplot(data = diamonds) + <strong>#dataset used for ggplot now is diamonds</strong><br />
stat_count(mapping = aes(x = cut)) <strong>#This code creates the same plot as before, just using stat_count. This works because stat_count was the default stat for geom_bar.</strong></p>
<p>demo &lt;- tribble(<br />
~cut, ~freq,<br />
“Fair”, 1610,<br />
“Good”, 4906,<br />
“Very Good”, 12082,<br />
“Premium”, 13791,<br />
“Ideal”, 21551<br />
) <strong>#Used to override default stat by packing the frequency of the cut categories into a vector called demo. Takes into account the frequency of each category listed under the cut variable.</strong></p>
<p>ggplot(data = demo) + <strong>#New ggplot using new vector demo as the dataset</strong><br />
geom_bar(mapping = aes(x = cut, y = freq), stat = “identity”) <strong>#New bar chart mapping cut categories on the x-axis and their frequency on the y-axis.</strong></p>
<p>ggplot(data = diamonds) + <strong>gplot with diamonds as dataset</strong><br />
geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1)) <strong>#Bar chart with overriden default mapping from the transformed variables to aesthetics. The y-axis has been set to display a statistical transformation (stat) of proportion rather than count. The group=1 function specifies which row will be evaluated with the proportion.</strong></p>
<p>ggplot(data = diamonds) +<br />
stat_summary( <strong>#summarizes the y values for each unique x value</strong><br />
mapping = aes(x = cut, y = depth), <strong>#aesthetic mapping of the x and y axes</strong><br />
fun.min = min, <strong>#supplies the function minimum of the vector</strong><br />
fun.max = max, <strong>#Supplies the function maximum of the vector</strong><br />
fun = median <strong>#Supplies the function median of the vector</strong> )</p>
<p>ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, y = after_stat(prop))) <strong>#Bar chart with overriden default mapping from the transformed variables to aesthetics. The y-axis has been set to display a statistical transformation (stat) of proportion rather than count. Does not include group=1 so the proportion will end up being the whole dataset compared with the whole dataset (100).</strong> ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop))) <strong>#Same issue as previous bar chart, but includes the command fill=color so the bars will have color.</strong></p>
<p>ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, colour = cut)) <strong>#bar chart with color command so that each bin for the variable cut has its own outline</strong><br />
ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, fill = cut)) <strong>#bar chart with fill command that fills each bar for the variable cut with its own color</strong></p>
<p>ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, fill = clarity)) <strong>#bar chart with fill aesthetic applied to new variable, clarity so that each colored rectangle represents a combination of the two variables cut and clarity. The bars are stacked automatically.</strong></p>
<p>ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(alpha = 1/5, position = “identity”) <strong>#position=“identity” places the objects exactly where they fall in the graph, which causes overlaps of the bars. The alpha adjustment makes the bars slightly transparent.</strong> ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + geom_bar(fill = NA, position = “identity”) <strong>#position=“identity” places the objects exactly where they fall in the graph, which causes overlaps of the bars. fill=NA makes the bars completely transparent.</strong></p>
<p>ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, fill = clarity), position = “fill”) <strong>#position=“fill” command stacks the bars, but makes each set of bars the same height, making comparison easier.</strong></p>
<p>ggplot(data = diamonds) +<br />
geom_bar(mapping = aes(x = cut, fill = clarity), position = “dodge”) <strong>#position=“dodge” puts overlapping objects beside each other.</strong></p>
<p>ggplot(data = mpg) +<br />
geom_point(mapping = aes(x = displ, y = hwy), position = “jitter”) <strong>#position=“jitter” function adds a small amount of random noise to each point, which spreads points out because no two points are likely to receive the same amount of random noise.</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + <strong>#ggplot with mpg dataset. There is global mapping with cty as the x-axis and hwy as the y-axis</strong> geom_point() <strong>#scatterplot of the dataset with the global mapping of the axes</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + <strong>#ggplot with mpg dataset. There is global mapping with class as the x-axis and hwy as the y-axis</strong> geom_boxplot() ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + <strong>#ggplot with mpg dataset. There is global mapping with class as the x-axis and hwy as the y-axis</strong> geom_boxplot() + <strong>#creates boxplot of data</strong> coord_flip() <strong>#switches the x and y axes of the plot, which can help with issues of overlapping.</strong></p>
<p>nz &lt;- map_data(“nz”) <strong>#saves map_data into a new vector “nz”</strong></p>
<p>ggplot(nz, aes(long, lat, group = group)) + <strong>#map plot of nz with latitude (y-axis) and longitude (x-axis)</strong> geom_polygon(fill = “white”, colour = “black”) <strong>#polygon plot filled in white, outlined in black</strong></p>
<p>ggplot(nz, aes(long, lat, group = group)) + <strong>#map plot of nz with latitude (y-axis) and longitude (x-axis)</strong> geom_polygon(fill = “white”, colour = “black”) + coord_quickmap() <strong>#sets the aspect ratio correctly for maps, so the plotted map is not warped</strong></p>
<p>bar &lt;- ggplot(data = diamonds) + <strong>#saves chunk of code into a bar vector</strong> geom_bar( eom command for a bar chart mapping = aes(x = cut, fill = cut), <strong>#maps variable cut along the x axis, fills cut bars with color</strong> show.legend = FALSE, <strong>#no legend with the plot</strong> width = 1 <strong>#width of the plot set to 1</strong> ) + theme(aspect.ratio = 1) + <strong>#modify theme based on aspect ratio to equal one, making the plot a square</strong> labs(x = NULL, y = NULL) <strong>#No labels on either axes</strong></p>
<p>bar + coord_flip() <strong>#switches the y-axis with the x-axis for the bar</strong> bar + coord_polar() <strong>#uses polar coordinates to create a pie chart</strong></p>
<p>ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + <strong>#ggplot with mpg dataset. There is global mapping with cty as the x-axis and hwy as the y-axis</strong> geom_point() + <strong>#scatterplot</strong> geom_abline() + <strong>#Reference line added to plot</strong> coord_fixed() <strong>#Plot with fixed aspect ratio</strong></p>
<p><strong>Helpful code template for applying the functions described in the chapter. It includes seven parameters. Can be used to build any plot.</strong><br />
ggplot(data = <DATA>) + )) <strong>#empty graph for plotting dataset</strong><br />
<GEOM_FUNCTION>( <strong>geom function to plot actual layer</strong><br />
mapping = aes(<MAPPINGS>), <strong>#aesthetic mapping of variables</strong><br />
stat = <STAT>, <strong>#statistical transformation of plot</strong><br />
position = <POSITION> <strong>#position adjustment</strong> ) +<br />
<COORDINATE_FUNCTION> + <strong>#coordinate system of plot that can be adjusted</strong><br />
<FACET_FUNCTION> <strong>#Split plot into facets to display subsets of the data</strong></p>
</div>
<div id="graphics-for-communication" class="section level3">
<h3>Graphics for Communication</h3>
<p>library(tidyverse) <strong>#Run the package tidyverse in the library</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + <strong>#empty graph for plotting dataset</strong><br />
geom_point(aes(color = class)) + <strong>#scatterplot with color aesthetic applied to the variable class</strong><br />
geom_smooth(se = FALSE) + <strong>#adds a smooth fitted line. se=FALSE removes the confidence interval around the line</strong><br />
labs(title = “Fuel efficiency generally decreases with engine size”) <strong>#Creates a label for the title of the plot, which summarises the main finding</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + <strong>#same plot as above</strong><br />
geom_point(aes(color = class)) +<br />
geom_smooth(se = FALSE) +<br />
labs(<br />
title = “Fuel efficiency generally decreases with engine size”, <strong>#main title label above the plot</strong> subtitle = “Two seaters (sports cars) are an exception because of their light weight”, <strong>#subtitle for additional detail in a smaller font under the title</strong><br />
caption = “Data from fueleconomy.gov” <strong>#caption adds text at the bottom right of the plot, which can be used to display the data source</strong> )</p>
<p>ggplot(mpg, aes(displ, hwy)) + <strong>#same plot</strong><br />
geom_point(aes(colour = class)) +<br />
geom_smooth(se = FALSE) +<br />
labs(<br />
x = “Engine displacement (L)”, <strong>#replaces x-axis label</strong> y = “Highway fuel economy (mpg)”, <strong>#replaces y-axis label</strong> colour = “Car type” <strong>#renames the legend title</strong> )</p>
<p>df &lt;- tibble( <strong>#constructs a data frame named df</strong><br />
x = runif(10), <strong>#Generates 10 random numbers for x</strong><br />
y = runif(10) <strong>#Generates 10 random numbers for y</strong> )</p>
<p>ggplot(df, aes(x, y)) +<br />
geom_point() +<br />
labs( x = quote(sum(x[i] ^ 2, i == 1, n)), <strong>#quote() function allows a mathematical equation to be used as a label for the x-axis (instead of a string of text)</strong><br />
y = quote(alpha + beta + frac(delta, theta)) <strong>#mathematical equation used as y-axis label</strong> )</p>
<p>best_in_class &lt;- mpg %&gt;% <strong>#uses tibble to pull out specific information</strong> group_by(class) %&gt;% <strong>#specification of the variable from which the information is to be extracted</strong> filter(row_number(desc(hwy)) == 1) <strong>#filters one point by row for the variable</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(colour = class)) + <strong>#scatterplot</strong> geom_text(aes(label = model), data = best_in_class) <strong>#Geom_text like geom_point, but you can add labels to the actual plot. Labels the points specified using the tibble function.</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(colour = class)) + <strong>#normal scatterplot from before</strong> geom_label(aes(label = model), data = best_in_class, nudge_y = 2, alpha = 0.5) <strong>#Geom_label draws a rectangle behind the text, making it easier to read. label=model specifies what is to be labeled. nudge_y moves labels above the points by a factor of 2. alpha function makes the labels semi transparent by 0.5.</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(colour = class)) + <strong>#scatterplot mapped with color aesthetic for class</strong> geom_point(size = 3, shape = 1, data = best_in_class) + <strong>#New scatterplot layer with size and shape specifications for the points, which highlight the best_in_class points with a circle around them</strong> ggrepel::geom_label_repel(aes(label = model), data = best_in_class) <strong>#ggrepel function automatically adjusts labels so they do not overlap</strong></p>
<p>class_avg &lt;- mpg %&gt;% <strong>#new data frame for class_avg to be specified</strong> group_by(class) %&gt;% summarise( <strong>#new data frame for labeling</strong><br />
displ = median(displ), <strong>#computes median of x</strong><br />
hwy = median(hwy) <strong>#computes median of y</strong> )<br />
<code>summarise()</code> ungrouping output (override with <code>.groups</code> argument)</p>
<p>ggplot(mpg, aes(displ, hwy, colour = class)) + ggrepel::geom_label_repel(aes(label = class), <strong>#ggrepel to keep labels from overlapping. Aesthetic mapping to label class</strong> data = class_avg, <strong>#data labeled is class average</strong> size = 6, <strong>#plot size adjustment</strong> label.size = 0, <strong>#label size adjustment</strong> segment.color = NA <strong>#no specified segment color</strong> ) + geom_point() + <strong>#new scatterplot layer</strong> theme(legend.position = “none”) <strong>#turns the legend off</strong></p>
<p>label &lt;- mpg %&gt;% <strong>#new data frame</strong> summarise( <strong>#summarise() computes specific values of x and y</strong> displ = max(displ), <strong>#computes maximum x value</strong> hwy = max(hwy), <strong>#computes maximum y value</strong> label = “Increasing engine size is to decreasing fuel economy.” <strong>#label for the new plot put in the upper right corner of the data frame. ‘’ breaks label into lines</strong> )</p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point() + geom_text(aes(label = label), data = label, vjust = “top”, hjust = “right”) <strong>#scatterplot with specified label to be at upper right corner of the plot. vjust and hjust control the alignment of the label. They have nine combinations total</strong></p>
<p>label &lt;- tibble( <strong>#tibble creates new data frame</strong> displ = Inf, <strong>#Inf function puts label at the border fo the plot</strong> hwy = Inf, <strong>#label at the border of the plot</strong> label = “Increasing engine size is to decreasing fuel economy.” <strong>#label that will be written. ‘’ command breaks the label into lines</strong> )</p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point() + geom_text(aes(label = label), data = label, vjust = “top”, hjust = “right”) <strong>#label for plot at upper right corner now at the borders of the plot due to Inf command</strong></p>
<p>“Increasing engine size is related to decreasing fuel economy.” %&gt;% stringr::str_wrap(width = 40) %&gt;% <strong>#automatically adds line breaks based on specification of characters you want per line (in this case a maximum of 40)</strong> writeLines() <strong>#specification of the lines to be written</strong> Increasing engine size is related to decreasing fuel economy.</p>
<p>ggplot(mpg, aes(displ, hwy)) + <strong>#empty ggplot graph</strong> geom_point(aes(colour = class)) <strong>#scatterplot layer with aesthetic color for variable class</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) +<br />
geom_point(aes(colour = class)) +<br />
scale_x_continuous() + <strong>#x scale</strong><br />
scale_y_continuous() + <strong>#y scale</strong><br />
scale_colour_discrete() <strong>#default scales added by ggplot to each plot created (Format: scale_name of aesthetic_ name of scale dependent on the type of variable they align with)</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point() + scale_y_continuous(breaks = seq(15, 40, by = 5)) <strong>#breaks function overrides default choice to adjust the appearance of the ticks on the axes</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point() + scale_x_continuous(labels = NULL) + <strong>#labels=NULL suppresses the labels on the tick marks along the axes. Here for the x-axis</strong> scale_y_continuous(labels = NULL) <strong>#same for the y-axis</strong></p>
<p>presidential %&gt;% <strong>#New dataset presidential</strong> mutate(id = 33 + row_number()) %&gt;% <strong>#mutate() adds new variable without dropping existing ones</strong> ggplot(aes(start, id)) + geom_point() + <strong>#scatterplot layer</strong> geom_segment(aes(xend = end, yend = id)) + <strong>#geom_segment creates line segments. Draws a line between x/y and xend/yend</strong> scale_x_date(NULL, breaks = presidential$start, date_labels = “’%y”) <strong>#adjusts ticks on axes to highlight where observations occur, requires format specification</strong></p>
<p>base &lt;- ggplot(mpg, aes(displ, hwy)) + <strong>#ggplot saved as new vector “base”</strong> geom_point(aes(colour = class)) <strong>#scatterplot included in base</strong></p>
<p>base + theme(legend.position = “left”) <strong>#adjusts legend position to the left of the plot “base”</strong> base + theme(legend.position = “top”) <strong>#legend position above the plot</strong> base + theme(legend.position = “bottom”) <strong>#legend position below the plot</strong> base + theme(legend.position = “right”) # the default <strong>#default to have legend to the right of the plot</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(colour = class)) + geom_smooth(se = FALSE) + theme(legend.position = “bottom”) + <strong>#puts legend at the bottom of the plot</strong> guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4))) <strong>#Guides() controls the display of individual legends. guide_legend function shows control over the number of rows in the legend (nrow=) and overrides the original aesthetic to make the points larger (override.aes=list(size=)).</strong> <code>geom_smooth()</code> using method = ‘loess’ and formula ‘y ~ x’</p>
<p>ggplot(diamonds, aes(carat, price)) + <strong>#unstransformed variables</strong> geom_bin2d()</p>
<p>ggplot(diamonds, aes(log10(carat), log10(price))) + <strong>#log transform of variables carat and price from the original plot part of aesthetic mapping)) geom_bin2d() </strong>#geom_bin2d divides plot into rectangles, then counts the number of cases in each rectangle and maps the number of cases to the rectangle’s fill. Helpful for when scatterplot is overplotted.__</p>
<p>ggplot(diamonds, aes(carat, price)) + geom_bin2d() + scale_x_log10() + <strong>#x-axis adjusted to log scale</strong> scale_y_log10() <strong>#y-axis adjusted to log scale. Makes plot easier to read</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(color = drv)) <strong>#original scatterplot with default colors</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(color = drv)) + scale_colour_brewer(palette = “Set1”) <strong>#colors on scatterplot adjusted to be distinguishable by people with red-green color blindness</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point(aes(color = drv, shape = drv)) + <strong>#includes shape differences between the categories within the variable, making the graph interpretable in black and white</strong> scale_colour_brewer(palette = “Set1”) <strong>#red-green color blind adjustment</strong></p>
<p>presidential %&gt;% <strong>#presidential dataset</strong> mutate(id = 33 + row_number()) %&gt;% <strong>#adds variable</strong> ggplot(aes(start, id, colour = party)) + geom_point() + geom_segment(aes(xend = end, yend = id)) + <strong>#creates line segment with specified beginning and end</strong> scale_colour_manual(values = c(Republican = “red”, Democratic = “blue”)) <strong>#Uses predefined mapping between values and colors so Republican points are red and Democratic are blue.</strong></p>
<p>df &lt;- tibble( <strong>#constructs data frame df)</strong> x = rnorm(10000), <strong>#rnorm() generates random numbers in a normal distribution for x</strong> y = rnorm(10000) <strong>#does the same for y</strong> ) ggplot(df, aes(x, y)) + <strong>#ggplot with global aesthetic mapping of x and y specifications</strong> geom_hex() + <strong>#generates hexagonal map similar to geom_bin2d function</strong> coord_fixed() <strong>#plots with a fixed aspect ratio</strong></p>
<p>ggplot(df, aes(x, y)) + geom_hex() + viridis::scale_fill_viridis() + <strong>#continuous analog of the categorical ColorBrewer scales and uses the fill aesthetic to fill each hexagon with the color</strong> coord_fixed() <strong>#plots with fixed aspect ratio</strong></p>
<p>ggplot(df, aes(x, y)) + geom_hex() + <strong>#hexagonal mapping</strong> scale_colour_gradient(low = “white”, high = “red”) + <strong>#adds continuous color to create a gradient. Would need to use scale_fill_gradient2() if there is a diverging scale</strong> coord_fixed() <strong>#fixed aspect ratio</strong></p>
<p>ggplot(diamonds, aes(carat, price)) + <strong>#ggplot with diamonds dataset with aesthetic mapping for variables carat and price</strong> geom_point(aes(colour = cut), alpha = 1/20) <strong>#color aesthetic for variable cut, points are semitransparent through alpha by a factor of 1/20</strong></p>
<p>ggplot(mpg, mapping = aes(displ, hwy)) + geom_point(aes(color = class)) + geom_smooth() + coord_cartesian(xlim = c(5, 7), ylim = c(10, 30)) <strong>#zooms in on a region of the plot according to the specified x limits and y limits</strong></p>
<p>mpg %&gt;% <strong>#mpg data frame</strong> filter(displ &gt;= 5, displ &lt;= 7, hwy &gt;= 10, hwy &lt;= 30) %&gt;% <strong>#filter() shows cases in which the specified conditions are true. In this case it is between 5 and 7 for variable displ and between 10 and 30 for variable hwy</strong> ggplot(aes(displ, hwy)) + geom_point(aes(color = class)) + <strong>#scatterplot with color aesthetic for class variable</strong> geom_smooth() <strong>#new layer with smooth fitted line. Confidence interval around line is present because there is no command “se=FALSE”</strong></p>
<p>suv &lt;- mpg %&gt;% filter(class == “suv”) <strong>#Filters occurrences of suv from mpg and saves them into new data frame: suv</strong> compact &lt;- mpg %&gt;% filter(class == “compact”) <strong>#Filters occurrences of compact from mpg and saves them into new data frame: compact</strong></p>
<p>ggplot(suv, aes(displ, hwy, colour = drv)) + <strong>#ggplot for new data frame suv</strong> geom_point() <strong>#scatterplot for suv</strong></p>
<p>ggplot(compact, aes(displ, hwy, colour = drv)) + <strong>#ggplot for new data frame compact</strong> geom_point() <strong>#scatterplot for compact</strong> <strong>#2 separate plots for the two classes of cars, which are difficult to compare due to the differences in scales</strong></p>
<p>x_scale &lt;- scale_x_continuous(limits = range(mpg<span class="math inline">\(displ)) __#new scale for x with specified limits saved as x_scale__ y_scale &lt;- scale_y_continuous(limits = range(mpg\)</span>hwy)) <strong>#new scale for y with specified limits saved as y_scale</strong> col_scale &lt;- scale_colour_discrete(limits = unique(mpg$drv)) <strong>#new color scale with specified limits</strong></p>
<p>ggplot(suv, aes(displ, hwy, colour = drv)) + geom_point() + x_scale + y_scale + col_scale <strong>#all new scales applied to suv ggplot</strong></p>
<p>ggplot(compact, aes(displ, hwy, colour = drv)) + geom_point() + x_scale + y_scale + col_scale <strong>#all new scales applied to compact ggplot</strong> <strong>#Now both plots have the same scales and are easier to compare</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + <strong>#mpg ggplot</strong> geom_point(aes(color = class)) + <strong>#scatterplot layer with aesthetic mapping of color for variable class</strong> geom_smooth(se = FALSE) + <strong>#another layer with a smooth fitted line without the confidence interval</strong> theme_bw() <strong>#theme added to plot. theme_bw() is a white background with grid lines</strong></p>
<p>ggplot(mpg, aes(displ, hwy)) + geom_point() <strong>#ggplot of mpg that has been used with a scatterplot of the specified variables displ (x) and hwy (y)</strong></p>
<p>ggsave(“my-plot.pdf”) <strong>#ggsave() function saves the most recent plot to disk. No specifications of width and height for this code</strong> #&gt; Saving 7 x 4.33 in image<br />
<strong>#fig.width controls width</strong><br />
<strong>#fig.height controls height of the figure</strong><br />
<strong>#fig.asp is the aspect ratio</strong><br />
<strong>#out.width and out.height are the output widths and heights of the figure respectively. They need to be adjusted with fig.width and fig.height</strong><br />
<strong>#fig.show=“hold” shows plots after the code</strong><br />
<strong>#fig.cap adds a caption</strong><br />
<strong>#dev=“png” sets the graphics type to png, making plots more compact</strong></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
